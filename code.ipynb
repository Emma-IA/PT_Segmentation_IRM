{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"u2A_k6Ei7-su","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634732426139,"user_tz":-120,"elapsed":246,"user":{"displayName":"Alexandre Abela","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406946826645087890"}},"outputId":"aacd61e3-a83b-4725-cb12-83e13d543f56"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.optimizers import SGD,Adam\n","import os \n","import keras\n","from keras.preprocessing.image import load_img, smart_resize\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","import skimage.io as io\n","import skimage.transform as trans\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras import backend as keras\n","from google.colab import drive\n","drive.mount('drive')\n","!mkdir -p drive -v\n","cwd = os.getcwd()"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"TycrxlbT76lA","executionInfo":{"status":"ok","timestamp":1634732675350,"user_tz":-120,"elapsed":377,"user":{"displayName":"Alexandre Abela","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406946826645087890"}}},"source":["# PARAMS\n","VALIDATION_DATASET_SIZE = 10\n","DATASET_SIZE = 100\n","DATASET_PATH = 'drive/My Drive/projet_thematique/training'\n","TRAINING_IMAGE_SIZE = VALIDATION_IMAGE_SIZE = (216,256,10)\n","TRAINING_BATCH_SIZE = 3\n","VALIDATION_BATCH_SIZE = 3\n","NUMBER_OF_CHANNELS = 1\n","SHUFFLE_DATA = True\n","TRANSFORM = True\n","BATCH_SIZE = 10\n","CLASSES = 5\n","LEARNING_RATE = 0.001\n","PRETRAINED_WEIGHTS = None\n","NBR_CLASSES = 5"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BRQCL7uP6LWS"},"source":["DESCRIPTION :\n","The script provide helpers functions to handle nifti image format:\n","    - load_nii()\n","    - save_nii()\n","\n","to generate metrics for two images:\n","    - metrics()\n","\n","And it is callable from the command line (see below).\n","Each function provided in this script has comments to understand\n","how they works.\n","\n","HOW-TO:\n","\n","This script was tested for python 3.4.\n","\n","First, you need to install the required packages with\n","    pip install -r requirements.txt\n","\n","After the installation, you have two ways of running this script:\n","    1) python metrics.py ground_truth/patient001_ED.nii.gz prediction/patient001_ED.nii.gz\n","    2) python metrics.py ground_truth/ prediction/\n","\n","The first option will print in the console the dice and volume of each class for the given image.\n","The second option wiil ouput a csv file where each images will have the dice and volume of each class.\n","\n","\n","Link: http://acdc.creatis.insa-lyon.fr\n"]},{"cell_type":"code","metadata":{"id":"N0pKK6Xb9RLe","executionInfo":{"status":"ok","timestamp":1634732679978,"user_tz":-120,"elapsed":231,"user":{"displayName":"Alexandre Abela","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406946826645087890"}}},"source":["\"\"\"\n","author: Clément Zotti (clement.zotti@usherbrooke.ca)\n","date: April 2017\n","\n","DESCRIPTION :\n","The script provide helpers functions to handle nifti image format:\n","    - load_nii()\n","    - save_nii()\n","\n","to generate metrics for two images:\n","    - metrics()\n","\n","And it is callable from the command line (see below).\n","Each function provided in this script has comments to understand\n","how they works.\n","\n","HOW-TO:\n","\n","This script was tested for python 3.4.\n","\n","First, you need to install the required packages with\n","    pip install -r requirements.txt\n","\n","After the installation, you have two ways of running this script:\n","    1) python metrics.py ground_truth/patient001_ED.nii.gz prediction/patient001_ED.nii.gz\n","    2) python metrics.py ground_truth/ prediction/\n","\n","The first option will print in the console the dice and volume of each class for the given image.\n","The second option wiil ouput a csv file where each images will have the dice and volume of each class.\n","\n","\n","Link: http://acdc.creatis.insa-lyon.fr\n","\n","\"\"\"\n","\n","import os\n","from glob import glob\n","import time\n","import re\n","import argparse\n","import nibabel as nib\n","import pandas as pd\n","#from medpy.metric.binary import hd, dc\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","HEADER = [\"Name\", \"Dice LV\", \"Volume LV\", \"Err LV(ml)\",\n","          \"Dice RV\", \"Volume RV\", \"Err RV(ml)\",\n","          \"Dice MYO\", \"Volume MYO\", \"Err MYO(ml)\"]\n","\n","#\n","# Utils functions used to sort strings into a natural order\n","#\n","def conv_int(i):\n","    return int(i) if i.isdigit() else i\n","\n","\n","def natural_order(sord):\n","    \"\"\"\n","    Sort a (list,tuple) of strings into natural order.\n","\n","    Ex:\n","\n","    ['1','10','2'] -> ['1','2','10']\n","\n","    ['abc1def','ab10d','b2c','ab1d'] -> ['ab1d','ab10d', 'abc1def', 'b2c']\n","\n","    \"\"\"\n","    if isinstance(sord, tuple):\n","        sord = sord[0]\n","    return [conv_int(c) for c in re.split(r'(\\d+)', sord)]\n","\n","\n","#\n","# Utils function to load and save nifti files with the nibabel package\n","#\n","def load_nii(img_path):\n","    \"\"\"\n","    Function to load a 'nii' or 'nii.gz' file, The function returns\n","    everyting needed to save another 'nii' or 'nii.gz'\n","    in the same dimensional space, i.e. the affine matrix and the header\n","\n","    Parameters\n","    ----------\n","\n","    img_path: string\n","    String with the path of the 'nii' or 'nii.gz' image file name.\n","\n","    Returns\n","    -------\n","    Three element, the first is a numpy array of the image values,\n","    the second is the affine transformation of the image, and the\n","    last one is the header of the image.\n","    \"\"\"\n","    nimg = nib.load(img_path)\n","    return nimg.get_data(), nimg.affine, nimg.header\n","\n","\n","def save_nii(img_path, data, affine, header):\n","    \"\"\"\n","    Function to save a 'nii' or 'nii.gz' file.\n","\n","    Parameters\n","    ----------\n","\n","    img_path: string\n","    Path to save the image should be ending with '.nii' or '.nii.gz'.\n","\n","    data: np.array\n","    Numpy array of the image data.\n","\n","    affine: list of list or np.array\n","    The affine transformation to save with the image.\n","\n","    header: nib.Nifti1Header\n","    The header that define everything about the data\n","    (pleasecheck nibabel documentation).\n","    \"\"\"\n","    nimg = nib.Nifti1Image(data, affine=affine, header=header)\n","    nimg.to_filename(img_path)\n","\n","\n","#\n","# Functions to process files, directories and metrics\n","#\n","def metrics(img_gt, img_pred, voxel_size):\n","    \"\"\"\n","    Function to compute the metrics between two segmentation maps given as input.\n","\n","    Parameters\n","    ----------\n","    img_gt: np.array\n","    Array of the ground truth segmentation map.\n","\n","    img_pred: np.array\n","    Array of the predicted segmentation map.\n","\n","    voxel_size: list, tuple or np.array\n","    The size of a voxel of the images used to compute the volumes.\n","\n","    Return\n","    ------\n","    A list of metrics in this order, [Dice LV, Volume LV, Err LV(ml),\n","    Dice RV, Volume RV, Err RV(ml), Dice MYO, Volume MYO, Err MYO(ml)]\n","    \"\"\"\n","\n","    if img_gt.ndim != img_pred.ndim:\n","        raise ValueError(\"The arrays 'img_gt' and 'img_pred' should have the \"\n","                         \"same dimension, {} against {}\".format(img_gt.ndim,\n","                                                                img_pred.ndim))\n","\n","    res = []\n","    # Loop on each classes of the input images\n","    for c in [3, 1, 2]:\n","        # Copy the gt image to not alterate the input\n","        gt_c_i = np.copy(img_gt)\n","        gt_c_i[gt_c_i != c] = 0\n","\n","        # Copy the pred image to not alterate the input\n","        pred_c_i = np.copy(img_pred)\n","        pred_c_i[pred_c_i != c] = 0\n","\n","        # Clip the value to compute the volumes\n","        gt_c_i = np.clip(gt_c_i, 0, 1)\n","        pred_c_i = np.clip(pred_c_i, 0, 1)\n","\n","        # Compute the Dice\n","        dice = dc(gt_c_i, pred_c_i)\n","\n","        # Compute volume\n","        volpred = pred_c_i.sum() * np.prod(voxel_size) / 1000.\n","        volgt = gt_c_i.sum() * np.prod(voxel_size) / 1000.\n","\n","        res += [dice, volpred, volpred-volgt]\n","\n","    return res\n","\n","\n","def compute_metrics_on_files(path_gt, path_pred):\n","    \"\"\"\n","    Function to give the metrics for two files\n","\n","    Parameters\n","    ----------\n","\n","    path_gt: string\n","    Path of the ground truth image.\n","\n","    path_pred: string\n","    Path of the predicted image.\n","    \"\"\"\n","    gt, _, header = load_nii(path_gt)\n","    pred, _, _ = load_nii(path_pred)\n","    zooms = header.get_zooms()\n","\n","    name = os.path.basename(path_gt)\n","    name = name.split('.')[0]\n","    res = metrics(gt, pred, zooms)\n","    res = [\"{:.3f}\".format(r) for r in res]\n","\n","    formatting = \"{:>14}, {:>7}, {:>9}, {:>10}, {:>7}, {:>9}, {:>10}, {:>8}, {:>10}, {:>11}\"\n","    print(formatting.format(*HEADER))\n","    print(formatting.format(name, *res))\n","\n","\n","def compute_metrics_on_directories(dir_gt, dir_pred):\n","    \"\"\"\n","    Function to generate a csv file for each images of two directories.\n","\n","    Parameters\n","    ----------\n","\n","    path_gt: string\n","    Directory of the ground truth segmentation maps.\n","\n","    path_pred: string\n","    Directory of the predicted segmentation maps.\n","    \"\"\"\n","    lst_gt = sorted(glob(os.path.join(dir_gt, '*')), key=natural_order)\n","    lst_pred = sorted(glob(os.path.join(dir_pred, '*')), key=natural_order)\n","\n","    res = []\n","    for p_gt, p_pred in zip(lst_gt, lst_pred):\n","        if os.path.basename(p_gt) != os.path.basename(p_pred):\n","            raise ValueError(\"The two files don't have the same name\"\n","                             \" {}, {}.\".format(os.path.basename(p_gt),\n","                                               os.path.basename(p_pred)))\n","\n","        gt, _, header = load_nii(p_gt)\n","        pred, _, _ = load_nii(p_pred)\n","        zooms = header.get_zooms()\n","        res.append(metrics(gt, pred, zooms))\n","\n","    lst_name_gt = [os.path.basename(gt).split(\".\")[0] for gt in lst_gt]\n","    res = [[n,] + r for r, n in zip(res, lst_name_gt)]\n","    df = pd.DataFrame(res, columns=HEADER)\n","    df.to_csv(\"results_{}.csv\".format(time.strftime(\"%Y%m%d_%H%M%S\")), index=False)\n","\n","def main(path_gt, path_pred):\n","    \"\"\"\n","    Main function to select which method to apply on the input parameters.\n","    \"\"\"\n","    if os.path.isfile(path_gt) and os.path.isfile(path_pred):\n","        compute_metrics_on_files(path_gt, path_pred)\n","    elif os.path.isdir(path_gt) and os.path.isdir(path_pred):\n","        compute_metrics_on_directories(path_gt, path_pred)\n","    else:\n","        raise ValueError(\n","            \"The paths given needs to be two directories or two files.\")\n","\n","# main('./training/patient001/patient001_4d.nii.gz', './training/patient001/patient001_4d.nii.gz')\n","\n","def discover_dataset(path_gt, path_pred):\n","    gt, _, header = load_nii(path_gt)\n","    pred, _, _ = load_nii(path_pred)\n","    zooms = header.get_zooms()\n","#   print(len(pred))\n","#   print(len(pred[0]))\n","#   print(len(pred[0][0]))\n","#   print(len(pred[0][0][0]))\n","    return(pred)\n","\n","def read_file(path):\n","\n","    a=load_nii(path)\n","    plt.imshow(a[0][:,:,5])\n","    print(a[0])\n","    print(len(a[0]))\n","    print(len(a[0][0]))\n","    print(len(a[0][0][0]))\n","    \n","\n","# compute_metrics_on_files('./training/patient001/patient001_4d.nii.gz', './training/patient001/patient001_4d.nii.gz')\n","\n","# for i in range(10):\n","#     plt.figure() \n","#     plt.imshow(discover_dataset('./training/patient001/patient001_4d.nii.gz', './training/patient001/patient001_4d.nii.gz')[:,:,i,20])"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hjywzqRLxFBq"},"source":["# import"]},{"cell_type":"markdown","metadata":{"id":"7cAiup1szzdf"},"source":["parametres"]},{"cell_type":"markdown","metadata":{"id":"cPKT6U0KxSXL"},"source":["# générateurs"]},{"cell_type":"code","metadata":{"id":"-9m7NSco7mOK","executionInfo":{"status":"ok","timestamp":1634734601795,"user_tz":-120,"elapsed":253,"user":{"displayName":"Alexandre Abela","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406946826645087890"}}},"source":["def create_generators(data_path=DATASET_PATH):\n","    'Returns three generators'\n","    image_paths = []\n","    label_paths = []\n","    for i in range(1,DATASET_SIZE + 1):\n","      if i == 100:\n","        patient = 'patient' + str(i)\n","      elif i > 9:\n","        patient = 'patient0' + str(i)\n","      else:\n","        patient = 'patient00' + str(i)\n","\n","      folder_path = os.path.join(data_path, patient)\n","      image_paths.append(os.path.join(folder_path, patient+'_frame01.nii.gz'))\n","      image_paths.append(os.path.join(folder_path, patient+'_frame02.nii.gz'))\n","      label_paths.append(os.path.join(folder_path, patient+'_frame01_gt.nii.gz'))\n","      label_paths.append(os.path.join(folder_path, patient+'_frame02_gt.nii.gz'))\n","          \n","\n","    x_train_list, y_train_list, x_val_list, y_val_list = data_split(image_paths, label_paths)\n","\n","    train_data_generator = DataGeneratorClassifier(x_train_list, y_train_list,TRAINING_BATCH_SIZE, TRAINING_IMAGE_SIZE)\n","    validation_data_generator = DataGeneratorClassifier(x_val_list, y_val_list, VALIDATION_BATCH_SIZE, VALIDATION_IMAGE_SIZE, transform=False)\n","    return train_data_generator, validation_data_generator\n","\n","\n","def data_split(x_paths_list, y_paths_list):\n","    'Splits the paths list into three splits'\n","    # np.random.seed(0)\n","    # np.random.shuffle(paths_list)\n","    return x_paths_list[VALIDATION_DATASET_SIZE:], y_paths_list[VALIDATION_DATASET_SIZE:], x_paths_list[:VALIDATION_DATASET_SIZE], y_paths_list[:VALIDATION_DATASET_SIZE]\n","\n","\n","\n","\n","class DataGeneratorClassifier(tf.keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_IDs, list_labels, batch_size, image_size, data_path=DATASET_PATH, n_channels=NUMBER_OF_CHANNELS, shuffle=SHUFFLE_DATA, transform=TRANSFORM):\n","        'Initialisation'\n","        self.classes = os.listdir(data_path)\n","        self.image_size = image_size\n","        self.batch_size = BATCH_SIZE\n","        self.list_IDs = list_IDs\n","        self.list_labels = list_labels\n","        self.n_channels = n_channels\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","        self.data_path=data_path\n","        self.transform=transform\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        list_IDs_temp = []\n","        list_labels_temp = []\n","        for i in range(index*self.batch_size, (index+1)*self.batch_size):\n","          list_IDs_temp.append(self.list_IDs[i])\n","          list_labels_temp.append(self.list_labels[i])\n","\n","\n","        # indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","        # list_IDs_temp = self.list_IDs[indexes]\n","        # list_labels_temp = self.list_labels[indexes]\n","        X, y = self.__data_generation(list_IDs_temp, list_labels_temp)\n","        \n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","    # TODO\n","    def __data_generation(self, list_IDs_temp, list_labels_temp):\n","        'Generates data containing batch_size samples' # X : (n_samples, *image_size, n_channels)\n","        #X = np.empty((self.batch_size, *self.image_size, self.n_channels))\n","        #y = np.empty((self.batch_size, *self.image_size, self.n_channels), dtype=int)\n","\n","        X = []\n","        y = []\n","        for i, ID in enumerate(list_IDs_temp):\n","            \n","            Xi = load_nii(ID)\n","            # Xi = smart_resize(np.asarray(Xi), self.image_size)\n","            X.append(Xi)\n","\n","        for i, ID in enumerate(list_labels_temp):\n","            \n","            yi = load_nii(ID)\n","            y.append(yi)\n","\n","        # if self.transform:\n","        #     data_augmentation = tf.keras.Sequential([layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n","        #     layers.experimental.preprocessing.RandomRotation(0.8)])\n","        #     X=data_augmentation(X)\n","\n","        return X,y\n","\n","def show_batch(generator, batch_number=0):\n","    images, labels = generator.__getitem__(batch_number)\n","    fig,ax=plt.subplots(nrows=1, ncols=10)\n","    slices_indices=[1,2,3,4,5,6,7,8,9,10]\n","    for i in range(len(images)):\n","        for j in range(len(slices_indices)):\n","            images_slice=images[i,:,:,j]\n","            ax[j].imshow(images_slice,cmap='gray')\n","            ax[j].axis('off')\n","    plt.show"],"execution_count":77,"outputs":[]},{"cell_type":"code","metadata":{"id":"tu6-atNvq0q1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSL-t4WUARU0","executionInfo":{"status":"ok","timestamp":1634735043667,"user_tz":-120,"elapsed":588,"user":{"displayName":"Alexandre Abela","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01406946826645087890"}},"outputId":"53874901-7ea9-49d4-cc51-1fd63f545e8e"},"source":["gt,gv=create_generators(DATASET_PATH)\n","images,labels=gt.__getitem__(0)\n","print(images)\n","\n","#show_batch(gt,0)"],"execution_count":79,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:97: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n","\n","* deprecated from version: 3.0\n","* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"]},{"output_type":"stream","name":"stdout","text":["[(array([[[ 0,  0,  0, ...,  0,  0,  0],\n","        [ 0,  0,  0, ...,  0,  0,  0],\n","        [ 0,  0,  0, ...,  0,  0,  0],\n","        ...,\n","        [ 0,  0,  0, ...,  0,  0,  0],\n","        [ 0,  0,  0, ...,  0,  0,  0],\n","        [ 0,  0,  0, ...,  0,  0,  0]],\n","\n","       [[ 0,  1,  0, ...,  0,  0,  0],\n","        [ 0,  1,  2, ...,  0,  0,  1],\n","        [ 0,  1,  0, ...,  0,  2,  1],\n","        ...,\n","        [ 5,  0, 12, ...,  1, 17, 14],\n","        [ 8,  0, 12, ..., 12,  6, 10],\n","        [ 2,  0,  8, ...,  8,  6,  6]],\n","\n","       [[ 0,  3,  0, ...,  0,  0,  0],\n","        [ 0,  1,  0, ...,  2,  0,  1],\n","        [ 0,  1,  0, ...,  2,  1,  2],\n","        ...,\n","        [39,  0, 19, ..., 11, 15,  4],\n","        [29,  0,  7, ...,  1,  8,  6],\n","        [ 0,  0, 15, ..., 12, 13,  2]],\n","\n","       ...,\n","\n","       [[ 0, 38,  0, ...,  0,  0,  0],\n","        [13, 80, 47, ..., 13,  9, 14],\n","        [ 2, 94, 17, ..., 13, 22, 33],\n","        ...,\n","        [ 2,  0,  0, ...,  1,  1,  2],\n","        [ 2,  0,  2, ...,  1,  1,  2],\n","        [ 1,  0,  1, ...,  5,  4,  3]],\n","\n","       [[ 0, 11,  0, ...,  0,  0,  0],\n","        [ 6,  5,  2, ..., 45, 13,  0],\n","        [ 9,  0,  8, ...,  9, 27, 47],\n","        ...,\n","        [ 1,  0,  0, ...,  2,  3,  2],\n","        [ 1,  0,  1, ...,  1,  1,  3],\n","        [ 3,  0,  1, ...,  3,  4,  3]],\n","\n","       [[ 0, 11,  0, ...,  0,  0,  0],\n","        [ 9, 15,  2, ..., 27,  9,  9],\n","        [22, 12,  6, ...,  9, 40, 19],\n","        ...,\n","        [ 0,  0,  1, ...,  1,  2,  3],\n","        [ 0,  0,  0, ...,  1,  3,  1],\n","        [ 1,  0,  0, ...,  1,  4,  3]]], dtype=int16), array([[-1., -0.,  0.,  0.],\n","       [-0., -1.,  0.,  0.],\n","       [ 0.,  0.,  1.,  0.],\n","       [ 0.,  0.,  0.,  1.]]), <nibabel.nifti1.Nifti1Header object at 0x7ff1505fcfd0>), (array([[[  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        ...,\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0]],\n","\n","       [[  0,   4,   0, ...,   0,   0,   0],\n","        [  0,   2,   1, ...,   1,   0,   1],\n","        [  0,   1,   0, ...,   3,   1,   0],\n","        ...,\n","        [ 17,   0,  16, ...,  10,  15,  14],\n","        [ 17,   0,  28, ...,   6,  10,   6],\n","        [ 16,   0,  28, ...,   4,   4,   8]],\n","\n","       [[  0,   1,   0, ...,   0,   0,   0],\n","        [  0,   3,   2, ...,   3,   0,   1],\n","        [  0,   2,   3, ...,   1,   1,   2],\n","        ...,\n","        [ 45,   0,  31, ...,  11,  13,   4],\n","        [ 23,   0,  31, ...,   7,  32,   6],\n","        [  5,   0,   3, ...,  10,   6,   0]],\n","\n","       ...,\n","\n","       [[  0,  38,   0, ...,   0,   0,   0],\n","        [  2,  73,  37, ...,   4,  18,  33],\n","        [  6, 101,  15, ...,  13,  13,  18],\n","        ...,\n","        [  0,   0,   1, ...,   2,   3,   4],\n","        [  1,   0,   1, ...,   4,   6,   1],\n","        [  0,   0,   1, ...,   1,   2,   3]],\n","\n","       [[  0,   6,   0, ...,   0,   0,   0],\n","        [ 15,  12,   6, ...,  27,  13,  14],\n","        [  9,   3,   6, ...,  45,   9,  23],\n","        ...,\n","        [  1,   0,   0, ...,   2,   6,   4],\n","        [  0,   0,   0, ...,   5,   4,   2],\n","        [  0,   0,   0, ...,   2,   2,   3]],\n","\n","       [[  0,  16,   0, ...,   0,   0,   0],\n","        [ 11,  18,   2, ...,  45,   0,  23],\n","        [ 15,  24,   8, ...,  18,  13,   4],\n","        ...,\n","        [  0,   0,   1, ...,   3,   4,   2],\n","        [  0,   0,   0, ...,   3,   0,   1],\n","        [  0,   0,   0, ...,   1,   2,   0]]], dtype=int16), array([[-1., -0.,  0.,  0.],\n","       [-0., -1.,  0.,  0.],\n","       [ 0.,  0.,  1.,  0.],\n","       [ 0.,  0.,  0.,  1.]]), <nibabel.nifti1.Nifti1Header object at 0x7ff1505fc110>), (array([[[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 2, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 2, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 3, 0, 0],\n","        [0, 0, 0, ..., 2, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]], dtype=int16), array([[-1., -0.,  0.,  0.],\n","       [-0., -1.,  0.,  0.],\n","       [ 0.,  0.,  1.,  0.],\n","       [ 0.,  0.,  0.,  1.]]), <nibabel.nifti1.Nifti1Header object at 0x7ff1505fcf50>), (array([[[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 2, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 2, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 3, 0, 0],\n","        [0, 0, 0, ..., 2, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]], dtype=int16), array([[-1., -0.,  0.,  0.],\n","       [-0., -1.,  0.,  0.],\n","       [ 0.,  0.,  1.,  0.],\n","       [ 0.,  0.,  0.,  1.]]), <nibabel.nifti1.Nifti1Header object at 0x7ff1505fcc90>), (array([[[  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        ...,\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0]],\n","\n","       [[  0,   0,   0, ...,   0,   0,   0],\n","        [  7,   0,   0, ...,   0,   0,   0],\n","        [  4,   0,   0, ...,   0,   0,   0],\n","        ...,\n","        [323,   0,   0, ...,   0,   0,   0],\n","        [303,   0,   0, ...,   0,   0,   0],\n","        [291,   0,   0, ...,   0,   0,   0]],\n","\n","       [[  0,   0,   0, ...,   0,   0,   0],\n","        [  6,   0,   0, ...,   0,   0,   0],\n","        [  3,   0,   0, ...,   0,   0,   0],\n","        ...,\n","        [293,   0,   0, ...,   0,   0,   0],\n","        [323,   0,   0, ...,   0,   0,   0],\n","        [316,   0,   0, ...,   0,   0,   0]],\n","\n","       ...,\n","\n","       [[  0,   0,   0, ...,  41,  33,  24],\n","        [ 35,   0,   0, ...,  22,  26,  38],\n","        [ 12,  11,   0, ...,   6,  46,  17],\n","        ...,\n","        [  8,   6,  44, ...,   0,   0,   0],\n","        [ 10,  14,  23, ...,   0,   0,   0],\n","        [ 15,   8,  17, ...,   0,   0,   0]],\n","\n","       [[  0,   0,   0, ...,  51,  23,  31],\n","        [ 38,   0,   0, ...,  35,  29,  20],\n","        [ 54,  31,   0, ...,  25,   6,  38],\n","        ...,\n","        [ 15,  19,  12, ...,   0,   0,   0],\n","        [ 11,  22,  18, ...,   0,   0,   0],\n","        [ 15,  19,  22, ...,   0,   0,   0]],\n","\n","       [[  0,   0,   0, ...,  19,   6,  44],\n","        [ 32,   0,   0, ...,  48,  19,  38],\n","        [ 32,  13,   0, ...,  35,  26,  86],\n","        ...,\n","        [ 14,  12,  40, ...,   0,   0,   0],\n","        [ 17,  13,  25, ...,   0,   0,   0],\n","        [ 19,  18,  22, ...,   0,   0,   0]]], dtype=int16), array([[-1., -0.,  0.,  0.],\n","       [-0., -1.,  0.,  0.],\n","       [ 0.,  0.,  1.,  0.],\n","       [ 0.,  0.,  0.,  1.]]), <nibabel.nifti1.Nifti1Header object at 0x7ff1505fc5d0>), (array([[[  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        ...,\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0],\n","        [  0,   0,   0, ...,   0,   0,   0]],\n","\n","       [[  0,   0,   0, ...,   0,   0,   0],\n","        [  9,   0,   0, ...,   0,   0,   0],\n","        [ 11,   0,   0, ...,   0,   0,   0],\n","        ...,\n","        [282,   0,   0, ...,   0,   0,   0],\n","        [341,   0,   0, ...,   0,   0,   0],\n","        [295,   0,   0, ...,   0,   0,   0]],\n","\n","       [[  0,   0,   0, ...,   0,   0,   0],\n","        [  3,   0,   0, ...,   0,   0,   0],\n","        [  5,   0,   0, ...,   0,   0,   0],\n","        ...,\n","        [340,   0,   0, ...,   0,   0,   0],\n","        [317,   0,   0, ...,   0,   0,   0],\n","        [316,   0,   0, ...,   0,   0,   0]],\n","\n","       ...,\n","\n","       [[  0,   0,   0, ...,  19,  26,  27],\n","        [ 48,   0,   0, ...,  28,  19,  17],\n","        [ 51,  11,   0, ...,  42,  73,  27],\n","        ...,\n","        [  6,   5,  35, ...,   0,   0,   0],\n","        [ 13,  19,  19, ...,   0,   0,   0],\n","        [ 21,  19,   8, ...,   0,   0,   0]],\n","\n","       [[  0,   0,   0, ...,  63,  19,  17],\n","        [ 38,   0,   0, ...,  45,  33,  41],\n","        [ 32,  39,   0, ...,  29,  73,  48],\n","        ...,\n","        [ 15,  17,   7, ...,   0,   0,   0],\n","        [ 10,  19,  12, ...,   0,   0,   0],\n","        [ 15,  17,  18, ...,   0,   0,   0]],\n","\n","       [[  0,   0,   0, ...,  22,  75,  41],\n","        [ 19,   0,   0, ...,  22,  19,  38],\n","        [ 38,   8,   0, ...,  45,  53,  24],\n","        ...,\n","        [  8,  21,  40, ...,   0,   0,   0],\n","        [ 14,   5,  21, ...,   0,   0,   0],\n","        [ 14,  19,  15, ...,   0,   0,   0]]], dtype=int16), array([[-1., -0.,  0.,  0.],\n","       [-0., -1.,  0.,  0.],\n","       [ 0.,  0.,  1.,  0.],\n","       [ 0.,  0.,  0.,  1.]]), <nibabel.nifti1.Nifti1Header object at 0x7ff1505fc950>), (array([[[ 6.,  8.,  8., ...,  4.,  4.,  3.],\n","        [ 6.,  8.,  8., ...,  4.,  4.,  3.],\n","        [ 6.,  8.,  8., ...,  4.,  4.,  3.],\n","        ...,\n","        [ 6.,  8.,  8., ...,  4.,  4.,  3.],\n","        [ 6.,  8.,  8., ...,  4.,  4.,  3.],\n","        [ 6.,  8.,  8., ...,  4.,  4.,  3.]],\n","\n","       [[ 6.,  8.,  8., ...,  4.,  4.,  3.],\n","        [ 8., 10., 12., ...,  5.,  4.,  4.],\n","        [ 8., 12., 10., ...,  5.,  4.,  4.],\n","        ...,\n","        [ 7.,  8.,  8., ...,  5.,  5.,  3.],\n","        [ 7.,  8.,  8., ...,  5.,  5.,  4.],\n","        [ 7.,  9.,  8., ...,  5.,  5.,  4.]],\n","\n","       [[ 6.,  8.,  8., ...,  4.,  4.,  3.],\n","        [ 8., 10., 12., ...,  4.,  4.,  4.],\n","        [ 8., 13., 12., ...,  5.,  4.,  4.],\n","        ...,\n","        [ 7.,  8.,  9., ...,  5.,  5.,  4.],\n","        [ 7.,  8.,  9., ...,  5.,  5.,  4.],\n","        [ 7.,  9.,  8., ...,  5.,  5.,  4.]],\n","\n","       ...,\n","\n","       [[ 6.,  8.,  8., ...,  4.,  4.,  3.],\n","        [ 8.,  9.,  8., ...,  6.,  6.,  6.],\n","        [ 9.,  8., 10., ...,  5.,  4.,  6.],\n","        ...,\n","        [ 7.,  8.,  8., ...,  5.,  4.,  4.],\n","        [ 7.,  8.,  9., ...,  4.,  4.,  4.],\n","        [ 6.,  8.,  8., ...,  5.,  4.,  3.]],\n","\n","       [[ 6.,  8.,  8., ...,  4.,  4.,  3.],\n","        [ 7.,  9.,  9., ...,  6.,  6., 10.],\n","        [ 8.,  8., 11., ...,  5.,  5.,  4.],\n","        ...,\n","        [ 7.,  8., 10., ...,  5.,  4.,  4.],\n","        [ 6.,  8.,  9., ...,  5.,  5.,  3.],\n","        [ 7.,  8.,  8., ...,  5.,  4.,  3.]],\n","\n","       [[ 6.,  8.,  8., ...,  4.,  4.,  3.],\n","        [ 7.,  9.,  8., ...,  5.,  4.,  6.],\n","        [ 6., 10.,  9., ...,  7.,  4.,  5.],\n","        ...,\n","        [ 6.,  8.,  8., ...,  5.,  4.,  3.],\n","        [ 7.,  8.,  9., ...,  5.,  4.,  3.],\n","        [ 7.,  8.,  9., ...,  5.,  4.,  3.]]], dtype=float32), array([[-1., -0.,  0.,  0.],\n","       [-0., -1.,  0.,  0.],\n","       [ 0.,  0.,  1.,  0.],\n","       [ 0.,  0.,  0.,  1.]]), <nibabel.nifti1.Nifti1Header object at 0x7ff1505fcb50>), (array([[[ 7.,  9., 12., ...,  5.,  4.,  3.],\n","        [ 7.,  9., 12., ...,  5.,  4.,  3.],\n","        [ 7.,  9., 12., ...,  5.,  4.,  3.],\n","        ...,\n","        [ 7.,  9., 12., ...,  5.,  4.,  3.],\n","        [ 7.,  9., 12., ...,  5.,  4.,  3.],\n","        [ 7.,  9., 12., ...,  5.,  4.,  3.]],\n","\n","       [[ 7.,  9., 12., ...,  5.,  4.,  3.],\n","        [ 9., 13., 16., ...,  5.,  4.,  3.],\n","        [ 8., 12., 15., ...,  5.,  4.,  4.],\n","        ...,\n","        [ 8., 10., 13., ...,  5.,  5.,  4.],\n","        [ 8., 10., 13., ...,  6.,  5.,  4.],\n","        [ 8.,  9., 13., ...,  6.,  4.,  4.]],\n","\n","       [[ 7.,  9., 12., ...,  5.,  4.,  3.],\n","        [11., 13., 16., ...,  5.,  4.,  3.],\n","        [10.,  9., 15., ...,  5.,  4.,  3.],\n","        ...,\n","        [ 8., 10., 13., ...,  5.,  5.,  5.],\n","        [ 8., 10., 13., ...,  5.,  5.,  4.],\n","        [ 8., 10., 13., ...,  5.,  4.,  4.]],\n","\n","       ...,\n","\n","       [[ 7.,  9., 12., ...,  5.,  4.,  3.],\n","        [ 8., 10., 12., ...,  7.,  6.,  5.],\n","        [ 8., 11., 13., ...,  8.,  5.,  4.],\n","        ...,\n","        [ 8., 10., 13., ...,  5.,  4.,  4.],\n","        [ 8., 10., 12., ...,  5.,  4.,  4.],\n","        [ 8.,  9., 13., ...,  5.,  4.,  4.]],\n","\n","       [[ 7.,  9., 12., ...,  5.,  4.,  3.],\n","        [ 8., 10., 13., ...,  7.,  4.,  6.],\n","        [ 8., 10., 14., ...,  6.,  6.,  4.],\n","        ...,\n","        [ 8.,  9., 12., ...,  5.,  4.,  4.],\n","        [ 8.,  9., 13., ...,  5.,  4.,  4.],\n","        [ 8., 10., 13., ...,  5.,  4.,  4.]],\n","\n","       [[ 7.,  9., 12., ...,  5.,  4.,  3.],\n","        [ 7., 10., 13., ...,  5.,  5.,  5.],\n","        [ 7., 10., 14., ...,  7.,  6.,  5.],\n","        ...,\n","        [ 8., 10., 13., ...,  5.,  4.,  4.],\n","        [ 8., 10., 12., ...,  5.,  4.,  4.],\n","        [ 8., 10., 13., ...,  5.,  4.,  4.]]], dtype=float32), array([[-1., -0.,  0.,  0.],\n","       [-0., -1.,  0.,  0.],\n","       [ 0.,  0.,  1.,  0.],\n","       [ 0.,  0.,  0.,  1.]]), <nibabel.nifti1.Nifti1Header object at 0x7ff1505fcd90>), (array([[[ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        ...,\n","        [ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 8.,  8.,  8., ...,  8.,  8.,  9.]],\n","\n","       [[ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 9., 11.,  8., ...,  8.,  8.,  9.],\n","        [10.,  9.,  9., ...,  8.,  8.,  9.],\n","        ...,\n","        [ 9., 10.,  9., ..., 10.,  8.,  9.],\n","        [ 8., 10.,  9., ...,  9.,  9., 10.],\n","        [ 9.,  8.,  8., ...,  9.,  8., 10.]],\n","\n","       [[ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 9., 10.,  8., ...,  8.,  8.,  9.],\n","        [ 9.,  8.,  9., ...,  8.,  8.,  9.],\n","        ...,\n","        [ 9.,  9.,  9., ...,  9.,  9.,  9.],\n","        [ 9., 10.,  9., ...,  8.,  9.,  9.],\n","        [10.,  9.,  8., ..., 10.,  8., 10.]],\n","\n","       ...,\n","\n","       [[ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 9.,  9.,  9., ...,  8., 10., 10.],\n","        [ 8.,  8.,  9., ..., 10.,  9., 10.],\n","        ...,\n","        [ 8.,  8.,  8., ...,  9.,  8.,  9.],\n","        [ 8.,  8.,  8., ...,  9.,  9.,  9.],\n","        [ 8.,  8.,  8., ...,  8.,  9.,  9.]],\n","\n","       [[ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 9.,  9.,  8., ...,  9.,  9., 10.],\n","        [ 8.,  8.,  8., ...,  9.,  9.,  9.],\n","        ...,\n","        [ 8.,  8.,  8., ...,  8.,  8., 10.],\n","        [ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 8.,  8.,  8., ...,  8.,  8.,  9.]],\n","\n","       [[ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 9.,  9.,  9., ..., 10.,  9., 10.],\n","        [ 8.,  9.,  8., ...,  8., 10.,  9.],\n","        ...,\n","        [ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 8.,  8.,  8., ...,  8.,  8., 10.],\n","        [ 8.,  8.,  8., ...,  8.,  8.,  9.]]], dtype=float32), array([[-1., -0.,  0.,  0.],\n","       [-0., -1.,  0.,  0.],\n","       [ 0.,  0.,  1.,  0.],\n","       [ 0.,  0.,  0.,  1.]]), <nibabel.nifti1.Nifti1Header object at 0x7ff1505fca90>), (array([[[ 7.,  7.,  7., ...,  8.,  8.,  9.],\n","        [ 7.,  7.,  7., ...,  8.,  8.,  9.],\n","        [ 7.,  7.,  7., ...,  8.,  8.,  9.],\n","        ...,\n","        [ 7.,  7.,  7., ...,  8.,  8.,  9.],\n","        [ 7.,  7.,  7., ...,  8.,  8.,  9.],\n","        [ 7.,  7.,  7., ...,  8.,  8.,  9.]],\n","\n","       [[ 7.,  7.,  7., ...,  8.,  8.,  9.],\n","        [ 9.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 7., 10.,  9., ...,  8.,  9.,  9.],\n","        ...,\n","        [ 8., 10.,  8., ...,  9.,  8., 10.],\n","        [ 8.,  9.,  8., ..., 10.,  9.,  9.],\n","        [ 8.,  9.,  8., ..., 10.,  9., 10.]],\n","\n","       [[ 7.,  7.,  7., ...,  8.,  8.,  9.],\n","        [10.,  9.,  7., ...,  8.,  8.,  9.],\n","        [ 9., 10.,  8., ...,  8.,  8.,  9.],\n","        ...,\n","        [ 7.,  9.,  8., ...,  9.,  8.,  9.],\n","        [ 9.,  8.,  7., ...,  9.,  8.,  9.],\n","        [ 8., 10.,  8., ..., 10.,  8., 10.]],\n","\n","       ...,\n","\n","       [[ 7.,  7.,  7., ...,  8.,  8.,  9.],\n","        [ 9.,  9.,  7., ...,  8.,  9., 11.],\n","        [ 8., 11.,  8., ...,  8., 10., 11.],\n","        ...,\n","        [ 7.,  8.,  8., ...,  9.,  9.,  9.],\n","        [ 7.,  7.,  8., ...,  9.,  8., 10.],\n","        [ 7.,  7.,  8., ...,  8.,  8.,  9.]],\n","\n","       [[ 7.,  7.,  7., ...,  8.,  8.,  9.],\n","        [ 8.,  9.,  8., ...,  9., 11., 10.],\n","        [ 7., 10.,  8., ..., 11., 10., 11.],\n","        ...,\n","        [ 8.,  7.,  8., ...,  8.,  9.,  9.],\n","        [ 7.,  8.,  8., ...,  8.,  8., 10.],\n","        [ 7.,  7.,  7., ...,  8.,  9., 10.]],\n","\n","       [[ 7.,  7.,  7., ...,  8.,  8.,  9.],\n","        [ 8., 11.,  8., ...,  9.,  9., 10.],\n","        [ 9., 12.,  8., ...,  9.,  9.,  9.],\n","        ...,\n","        [ 8.,  8.,  8., ...,  8.,  8.,  9.],\n","        [ 8.,  8.,  8., ...,  8.,  8., 10.],\n","        [ 7.,  7.,  7., ...,  8.,  8., 10.]]], dtype=float32), array([[-1., -0.,  0.,  0.],\n","       [-0., -1.,  0.,  0.],\n","       [ 0.,  0.,  1.,  0.],\n","       [ 0.,  0.,  0.,  1.]]), <nibabel.nifti1.Nifti1Header object at 0x7ff1505fcad0>)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"gzmqUpDdxWuc"},"source":["# model"]},{"cell_type":"code","metadata":{"id":"OpWbSA43xBJl"},"source":["def unet(pretrained_weights = PRETRAINED_WEIGHTS,input_size = (TRAINING_IMAGE_SIZE[0],TRAINING_IMAGE_SIZE[1],TRAINING_IMAGE_SIZE[2],NUMBER_OF_CHANNELS)):\n","#     inputs = tf.random.normal(input_size)\n","    inputs = Input(input_size, batch_size = BATCH_SIZE)\n","    conv1 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    pool1 = MaxPooling3D(pool_size=(2, 2, 1))(conv1)\n","    conv2 = Conv3D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv3D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPooling3D(pool_size=(2, 2, 1))(conv2)\n","    conv3 = Conv3D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv3D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    drop3 = Dropout(0.5)(conv3)\n","    pool3 = MaxPooling3D(pool_size=(2, 2, 1))(drop3)\n","\n","    conv4 = Conv3D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv3D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    # pool4 = MaxPooling3D(pool_size=(2, 2, 1))(drop4)\n","    # conv5 = Conv3D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    # conv5 = Conv3D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    # drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv3D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,1))(drop4))\n","    merge6 = concatenate([drop3,up6], axis = 4)\n","    conv6 = Conv3D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv3D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","    up7 = Conv3D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,1))(conv6))\n","    merge7 = concatenate([conv2,up7], axis = 4)\n","    conv7 = Conv3D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv3D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","    up8 = Conv3D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,1))(conv7))\n","    merge8 = concatenate([conv1,up8], axis = 4)\n","    conv8 = Conv3D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv3D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    # up9 = Conv3D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling3D(size = (2,2,1))(conv8))\n","    # merge9 = concatenate([conv1,up9], axis = 4)\n","    # conv9 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    # conv9 = Conv3D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv3D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","    conv10 = Conv3D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = Model(inputs = inputs, outputs = conv10)\n","\n","    model.compile(optimizer = Adam(lr = LEARNING_RATE), loss = 'binary_crossentropy', metrics = tf.keras.metrics.MeanIoU(num_classes=NBR_CLASSES))\n","    \n","    model.summary()\n","\n","    if(pretrained_weights):\n","        model.load_weights(pretrained_weights)\n","\n","    return model\n","\n","unet()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Yg4XFngi3Yo"},"source":[""],"execution_count":null,"outputs":[]}]}